{"pageProps":{"quiz":{"folder":"hadoop","path":"data/hadoop/hadoop-quiz.md","questions":[{"text":"#### Q1. Partitioner controls the partitioning of what data?\n\n-  final keys\n-  final values\n-  intermediate keys\n-  intermediate values\n\n","options":3,"answer":2},{"text":"#### Q2. SQL Windowing functions are implemented in Hive using which keywords?\n\n-  UNION DISTINCT, RANK\n-  OVER, RANK\n-  OVER, EXCEPT\n-  UNION DISTINCT, RANK\n\n","options":3,"answer":1},{"text":"#### Q3. Rather than adding a Secondary Sort to a slow Reduce job, it is Hadoop best practice to perform which optimization?\n\n-  Add a partitioned shuffle to the Map job.\n-  Add a partitioned shuffle to the Reduce job.\n-  Break the Reduce job into multiple, chained Reduce jobs.\n-  Break the Reduce job into multiple, chained Map jobs.\n\n","options":3,"answer":1},{"text":"#### Q4. Hadoop Auth enforces authentication on protected resources. Once authentication has been established, it sets what type of authenticating cookie?\n\n-  encrypted HTTP\n-  unsigned HTTP\n-  compressed HTTP\n-  signed HTTP\n\n","options":3,"answer":3},{"text":"#### Q5. MapReduce jobs can be written in which language?\n\n-  Java or Python\n-  SQL only\n-  SQL or Java\n-  Python or SQL\n\n","options":3,"answer":0},{"text":"#### Q6. To perform local aggregation of the intermediate outputs, MapReduce users can optionally specify which object?\n\n-  Reducer\n-  Combiner\n-  Mapper\n-  Counter\n\n","options":3,"answer":1},{"text":"#### Q7. To verify job status, look for the value `___` in the `___`.\n\n-  SUCCEEDED; syslog\n-  SUCCEEDED; stdout\n-  DONE; syslog\n-  DONE; stdout\n\n","options":3,"answer":1},{"text":"#### Q8. Which line of code implements a Reducer method in MapReduce 2.0?\n\n-  public void reduce(Text key, Iterator<IntWritable> values, Context context){…}\n-  public static void reduce(Text key, IntWritable[] values, Context context){…}\n-  public static void reduce(Text key, Iterator<IntWritable> values, Context context){…}\n-  public void reduce(Text key, IntWritable[] values, Context context){…}\n\n","options":3,"answer":0},{"text":"#### Q9. To get the total number of mapped input records in a map job task, you should review the value of which counter?\n\n-  FileInputFormatCounter\n-  FileSystemCounter\n-  JobCounter\n-  TaskCounter (NOT SURE)\n\n","options":3,"answer":3},{"text":"#### Q10. Hadoop Core supports which CAP capabilities?\n\n-  A, P\n-  C, A\n-  C, P\n-  C, A, P\n\n","options":3,"answer":0},{"text":"#### Q11. What are the primary phases of a Reducer?\n\n-  combine, map, and reduce\n-  shuffle, sort, and reduce\n-  reduce, sort, and combine\n-  map, sort, and combine\n\n","options":3,"answer":1},{"text":"#### Q12. To set up Hadoop workflow with synchronization of data between jobs that process tasks both on disk and in memory, use the `___` service, which is `___`.\n\n-  Oozie; open source\n-  Oozie; commercial software\n-  Zookeeper; commercial software\n-  Zookeeper; open source\n\n","options":3,"answer":3},{"text":"#### Q13. For high availability, use multiple nodes of which type?\n\n-  data\n-  name\n-  memory\n-  worker\n\n","options":3,"answer":1},{"text":"#### Q14. DataNode supports which type of drives?\n\n-  hot swappable\n-  cold swappable\n-  warm swappable\n-  non-swappable\n\n","options":3,"answer":0},{"text":"#### Q15. Which method is used to implement Spark jobs?\n\n-  on disk of all workers\n-  on disk of the master node\n-  in memory of the master node\n-  in memory of all workers\n\n","options":3,"answer":3},{"text":"#### Q16. In a MapReduce job, where does the map() function run?\n\n-  on the reducer nodes of the cluster\n-  on the data nodes of the cluster (NOT SURE)\n-  on the master node of the cluster\n-  on every node of the cluster\n\n","options":3,"answer":1},{"text":"#### Q17. To reference a master file for lookups during Mapping, what type of cache should be used?\n\n-  distributed cache\n-  local cache\n-  partitioned cache\n-  cluster cache\n\n","options":3,"answer":0},{"text":"#### Q18. Skip bad records provides an option where a certain set of bad input records can be skipped when processing what type of data?\n\n-  cache inputs\n-  reducer inputs\n-  intermediate values\n-  map inputs\n\n","options":3,"answer":3},{"text":"#### Q19. Which command imports data to Hadoop from a MySQL database?\n\n-  spark import --connect jdbc:mysql://mysql.example.com/spark --username spark --warehouse-dir user/hue/oozie/deployments/spark\n-  sqoop import --connect jdbc:mysql://mysql.example.com/sqoop --username sqoop --warehouse-dir user/hue/oozie/deployments/sqoop\n-  sqoop import --connect jdbc:mysql://mysql.example.com/sqoop --username sqoop --password sqoop --warehouse-dir user/hue/oozie/deployments/sqoop\n-  spark import --connect jdbc:mysql://mysql.example.com/spark --username spark --password spark --warehouse-dir user/hue/oozie/deployments/spark\n\n","options":3,"answer":2},{"text":"#### Q20. In what form is Reducer output presented?\n\n-  compressed (NOT SURE)\n-  sorted\n-  not sorted\n-  encrypted\n\n","options":3,"answer":0},{"text":"#### Q21. Which library should be used to unit test MapReduce code?\n\n-  JUnit\n-  XUnit\n-  MRUnit\n-  HadoopUnit\n\n","options":3,"answer":2},{"text":"#### Q22. If you started the NameNode, then which kind of user must you be?\n\n-  hadoop-user\n-  super-user\n-  node-user\n-  admin-user\n\n","options":3,"answer":1},{"text":"#### Q23. State \\_ between the JVMs in a MapReduce job\n\n-  can be configured to be shared\n-  is partially shared\n-  is shared\n-  is not shared (https://www.lynda.com/Hadoop-tutorials/Understanding-Java-virtual-machines-JVMs/191942/369545-4.html)\n\n","options":3,"answer":3},{"text":"#### Q24. To create a MapReduce job, what should be coded first?\n\n-  a static job() method\n-  a Job class and instance (NOT SURE)\n-  a job() method\n-  a static Job class\n\n","options":3,"answer":1},{"text":"#### Q25. To connect Hadoop to AWS S3, which client should you use?\n\n-  S3A\n-  S3N\n-  S3\n-  the EMR S3\n\n","options":3,"answer":0},{"text":"#### Q26. HBase works with which type of schema enforcement?\n\n-  schema on write\n-  no schema\n-  external schema\n-  schema on read\n\n","options":3,"answer":3},{"text":"#### Q27. HDFS file are of what type?\n\n-  read-write\n-  read-only\n-  write-only\n-  append-only\n\n","options":3,"answer":3},{"text":"#### Q28. A distributed cache file path can originate from what location?\n\n-  hdfs or top\n-  http\n-  hdfs or http\n-  hdfs\n\n","options":3,"answer":2},{"text":"#### Q29. Which library should you use to perform ETL-type MapReduce jobs?\n\n-  Hive\n-  Pig\n-  Impala\n-  Mahout\n\n","options":3,"answer":1},{"text":"#### Q30. What is the output of the Reducer?\n\n-  a relational table\n-  an update to the input file\n-  a single, combined list\n-  a set of <key, value> pairs\n\n`map function processes a certain key-value pair and emits a certain number of key-value pairs and the Reduce function processes values grouped by the same key and emits another set of key-value pairs as output.`\n\n","options":3,"answer":3},{"text":"#### Q31. To optimize a Mapper, what should you perform first?\n\n-  Override the default Partitioner.\n-  Skip bad records.\n-  Break up Mappers that do more than one task into multiple Mappers.\n-  Combine Mappers that do one task into large Mappers.\n\n","options":3,"answer":-1},{"text":"#### Q32. When implemented on a public cloud, with what does Hadoop processing interact?\n\n-  files in object storage\n-  graph data in graph databases\n-  relational data in managed RDBMS systems\n-  JSON data in NoSQL databases\n\n","options":3,"answer":0},{"text":"#### Q33. In the Hadoop system, what administrative mode is used for maintenance?\n\n-  data mode\n-  safe mode\n-  single-user mode\n-  pseudo-distributed mode\n\n","options":3,"answer":1},{"text":"#### Q34. In what format does RecordWriter write an output file?\n\n-  <key, value> pairs\n-  keys\n-  values\n-  <value, key> pairs\n\n","options":3,"answer":0},{"text":"#### Q35. To what does the Mapper map input key/value pairs?\n\n-  an average of keys for values\n-  a sum of keys for values\n-  a set of intermediate key/value pairs\n-  a set of final key/value pairs\n\n","options":3,"answer":2},{"text":"#### Q36. Which Hive query returns the first 1,000 values?\n\n-  SELECT…WHERE value = 1000\n-  SELECT … LIMIT 1000\n-  SELECT TOP 1000 …\n-  SELECT MAX 1000…\n\n","options":3,"answer":1},{"text":"#### Q37. To implement high availability, how many instances of the master node should you configure?\n\n-  one\n-  zero\n-  shared\n-  two or more (https://data-flair.training/blogs/hadoop-high-availability-tutorial)\n\n","options":3,"answer":3},{"text":"#### Q38. Hadoop 2.x and later implement which service as the resource coordinator?\n\n-  kubernetes\n-  JobManager\n-  JobTracker\n-  YARN\n\n","options":3,"answer":3},{"text":"#### Q39. In MapReduce, **\\_** have \\_\n\n-  tasks; jobs\n-  jobs; activities\n-  jobs; tasks\n-  activities; tasks\n\n","options":3,"answer":2},{"text":"#### Q40. What type of software is Hadoop Common?\n\n-  database\n-  distributed computing framework\n-  operating system\n-  productivity tool\n\n","options":3,"answer":1},{"text":"#### Q41. If no reduction is desired, you should set the numbers of \\_ tasks to zero\n\n-  combiner\n-  reduce\n-  mapper\n-  intermediate\n\n","options":3,"answer":1},{"text":"#### Q42. MapReduce applications use which of these classes to report their statistics?\n\n-  mapper\n-  reducer\n-  combiner\n-  counter\n\n","options":3,"answer":3},{"text":"#### Q43. \\_ is the query language, and \\_ is storage for NoSQL on Hadoop\n\n-  HDFS; HQL\n-  HQL; HBase\n-  HDFS; SQL\n-  SQL; HBase\n\n","options":3,"answer":1},{"text":"#### Q44. MapReduce 1.0 \\_ YARN\n\n-  does not include\n-  is the same thing as\n-  includes\n-  replaces\n\n","options":3,"answer":0},{"text":"#### Q45. Which type of Hadoop node executes file system namespace operations like opening, closing, and renaming files and directories?\n\n-  ControllerNode\n-  DataNode\n-  MetadataNode\n-  NameNode\n\n","options":3,"answer":3},{"text":"#### Q46. HQL queries produce which job types?\n\n-  Impala\n-  MapReduce\n-  Spark\n-  Pig\n\n","options":3,"answer":-1},{"text":"#### Q47. Suppose you are trying to finish a Pig script that converts text in the input string to uppercase. What code is needed on line 2 below?\n\n    1 data = LOAD '/user/hue/pig/examples/data/midsummer.txt'...\n    2\n\n-  as (text:CHAR[]); upper_case = FOREACH data GENERATE org.apache.pig.piggybank.evaluation.string.UPPER(TEXT);\n-  as (text:CHARARRAY); upper_case = FOREACH data GENERATE org.apache.pig.piggybank.evaluation.string.UPPER(TEXT);\n-  as (text:CHAR[]); upper_case = FOREACH data org.apache.pig.piggybank.evaluation.string.UPPER(TEXT);\n-  as (text:CHARARRAY); upper_case = FOREACH data org.apache.pig.piggybank.evaluation.string.UPPER(TEXT);\n\n","options":3,"answer":1},{"text":"#### Q48. In a MapReduce job, which phase runs after the Map phase completes?\n\n-  Combiner\n-  Reducer\n-  Map2\n-  Shuffle and Sort\n\n","options":3,"answer":0},{"text":"#### Q49. Where would you configure the size of a block in a Hadoop environment?\n\n-  dfs.block.size in hdfs-site.xmls\n-  orc.write.variable.length.blocks in hive-default.xml\n-  mapreduce.job.ubertask.maxbytes in mapred-site.xml\n-  hdfs.block.size in hdfs-site.xml\n\n","options":3,"answer":0},{"text":"#### Q50. Hadoop systems are **\\_** RDBMS systems.\n\n-  replacements for\n-  not used with\n-  substitutes for\n-  additions for\n\n","options":3,"answer":3},{"text":"#### Q51. Which object can be used to distribute jars or libraries for use in MapReduce tasks?\n\n-  distributed cache\n-  library manager\n-  lookup store\n-  registry\n\n","options":3,"answer":0},{"text":"#### Q52. To view the execution details of an Impala query plan, which function would you use ?\n\n-  explain\n-  query action\n-  detail\n-  query plan\n\n","options":3,"answer":0},{"text":"#### Q53. Which feature is used to roll back a corrupted HDFS instance to a previously known good point in time?\n\n-  partitioning\n-  snapshot\n-  replication\n-  high availability\n\n[Reference](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html#:~:text=is%20not%20supported.-,Snapshots,known%20good%20point%20in%20time.)\n\n","options":3,"answer":1},{"text":"#### Q54. Hadoop Common is written in which language?\n\n-  C++\n-  C\n-  Haskell\n-  Java\n\n","options":3,"answer":3},{"text":"#### Q55. Which file system does Hadoop use for storage?\n\n-  NAS\n-  FAT\n-  HDFS\n-  NFS\n\n","options":3,"answer":2},{"text":"#### Q56. What kind of storage and processing does Hadoop support?\n\n-  encrypted\n-  verified\n-  distributed\n-  remote\n\n","options":3,"answer":2},{"text":"#### Q57. Hadoop Common consists of which components?\n\n-  Spark and YARN\n-  HDFS and MapReduce\n-  HDFS and S3\n-  Spark and MapReduce\n\n","options":3,"answer":1},{"text":"#### Q58. Most Apache Hadoop committers' work is done at which commercial company?\n\n-  Cloudera\n-  Microsoft\n-  Google\n-  Amazon\n\n","options":3,"answer":3},{"text":"#### Q59. To get information about Reducer job runs, which object should be added?\n\n-  Reporter\n-  IntReadable\n-  IntWritable\n-  Writer\n\n","options":3,"answer":-1},{"text":"#### Q60. After changing the default block size and restarting the cluster, to which data does the new size apply?\n\n-  all data\n-  no data\n-  existing data\n-  new data\n\n","options":3,"answer":-1},{"text":"#### Q61. Which statement should you add to improve the performance of the following query?\n\n```\nSELECT\n  c.id,\n  c.name,\n  c.email_preferences.categories.surveys\nFROM customers c;\n```\n\n-  GROUP BY\n-  FILTER\n-  SUB-SELECT\n-  SORT\n\n","options":3,"answer":-1},{"text":"#### Q62. What custom object should you implement to reduce IO in MapReduce?\n\n-  Comparator\n-  Mapper\n-  Combiner\n-  Reducer\n\n","options":3,"answer":2},{"text":"#### Q63. You can optimize Hive queries using which method?\n\n-  secondary indices\n-  summary statistics\n-  column-based statistics\n-  a primary key index\n\n","options":3,"answer":-1},{"text":"#### Q64. If you are processing a single action on each input, what type of job should you create?\n\n-  partition-only\n-  map-only\n-  reduce-only\n-  combine-only\n\n","options":3,"answer":1},{"text":"#### Q65. The simplest possible MapReduce job optimization is to perform which of these actions?\n\n-  Add more master nodes.\n-  Implement optimized InputSplits.\n-  Add more DataNodes.\n-  Implement a custom Mapper.\n\n","options":3,"answer":1},{"text":"#### Q66. When you implement a custom Writable, you must also define which of these object?\n\n-  a sort policy\n-  a combiner policy\n-  a compression policy\n-  a filter policy\n\n","options":3,"answer":-1},{"text":"#### Q67. To copy a file into the Hadoop file system, what command should you use?\n\n-  hadoop fs -copy <fromDir> <toDir>\n-  hadoop fs -copy <toDir> <fromDir>\n-  hadoop fs -copyFromLocal <fromDir> <toDir>\n-  hadoop fs -copyFromLocal <toDir> <fromDir>\n\n","options":3,"answer":2},{"text":"#### Q68. delete a Hive ______ table and you will delete the table ______.\n    \n-  managed; metadata\n-  external; data and metadata\n-  external; metadata\n-  managed; data\n    \n","options":3,"answer":-1},{"text":" #### Q69. To see how Hive executed a JOIN operation, use the _ statement and look for the ____ value.\n-  EXPLAIN; JOIN Operator\n-  QUERY; MAP JOIN Operator\n-  EXPLAIN; MAP JOIN Operator\n-  QUERY; JOIN Operator\n\n","options":3,"answer":-1}],"title":"## Hadoop"},"lang":"en","availableLanguages":[{"isSelected":true,"name":"English","key":"en"}]},"__N_SSG":true}